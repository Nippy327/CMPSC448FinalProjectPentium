import os
import random
import shutil
import pathlib
import numpy as np
import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, MaxPool2D
from keras.optimizers import Adam

#Creates 3 folders for Train, Test, and Validation data
def split_dir_to_train_test_val(directory = "Users/samna/Documents/CMPSC 442/Boeing/MultiClassNonCamera/images/", train_size = 0.7, test_size = 0.2, val_size = 0.1):
    rng = random.Random(42)
    for root, folders, files in os.walk(directory):
        for folder in folders:
            #Create list of the files
            list_of_files = []
            for file_name in os.listdir(root+folder+"/"):
                list_of_files.append(file_name)
            
            #Shuffles the list
            rng.shuffle(list_of_files)

            #Creates lists of files
            train_files = list_of_files[:int(len(list_of_files)*train_size)]
            test_files = list_of_files[int(len(list_of_files)*train_size) : int(len(list_of_files)*(train_size+test_size))]
            val_files = list_of_files[int(len(list_of_files)*(train_size+test_size)):]

            #Creates folders and files for train data
            for one_file in train_files:
                #Copies files
                dest_dir = "files/train/"+folder+"/"
                os.makedirs(dest_dir, exist_ok=True)

                shutil.copy2(src=(root+folder+"/"+one_file), dst=(dest_dir+one_file))
            print(f"Folder {folder}. Train data copied. {len(train_files)} files")

            #Creates folders and files for test data
            for one_file in test_files:
                #Copies files
                dest_dir = "files/test/"+folder+"/"
                os.makedirs(dest_dir, exist_ok=True)

                shutil.copy2(src=(root+folder+"/"+one_file), dst=(dest_dir+one_file))
            print(f"Folder {folder}. Test data copied. {len(test_files)} files")

            #Creates folders and files for validation data
            for one_file in val_files:
                #Copies files
                dest_dir = "files/validation/"+folder+"/"
                os.makedirs(dest_dir, exist_ok=True)

                shutil.copy2(src=(root+folder+"/"+one_file), dst=(dest_dir+one_file))
            print(f"Folder {folder}. Validation data copied. {len(val_files)} files")


def get_class_names_from_folder(directory):
    data_dir = pathlib.Path(directory)
    class_names = np.array(sorted([item.name for item in data_dir.glob("*")])) #Creates a list of class names
    print(class_names)
    return class_names

split_dir_to_train_test_val(directory="Users/samna/Documents/CMPSC 442/Boeing/MultiClassNonCamera/images/", train_size=0.7, test_size=0.2, val_size=0.1)
class_names = get_class_names_from_folder(directory="files/train/")
print(class_names)

train_datagen = ImageDataGenerator(rescale=1/255.)
test_datagen = ImageDataGenerator(rescale=1/255.)
val_datagen = ImageDataGenerator(rescale=1/255.)

train_data = train_datagen.flow_from_directory(directory="files/train", target_size=(240,240), batch_size=32, class_mode="categorical")
test_data = test_datagen.flow_from_directory(directory="files/test", target_size=(240,240), batch_size=32, class_mode="categorical")
validation_data = val_datagen.flow_from_directory(directory="files/validation", target_size=(240,240), batch_size=32, class_mode="categorical")

tf.random.set_seed(42)

model = Sequential([Conv2D(10, 3, activation="relu", input_shape=(240, 240, 3)), MaxPool2D(pool_size=2), Conv2D(10, 3, activation="relu"), MaxPool2D(pool_size=2), Flatten(), Dense(3, activation="softmax")])

model.compile(loss="categorical_crossentropy", optimizer=Adam(), metrics=["accuracy"])

history = model.fit(train_data, batch_size=32, epochs=3, steps_per_epoch=len(train_data), validation_data=validation_data, validation_steps=len(validation_data))

model.evaluate(test_data)
